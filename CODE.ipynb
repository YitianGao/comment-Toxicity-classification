{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Toxicity Classification in Online Comments\n",
    "\n",
    "### Yitian Gao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read csv\n",
    "# df = pd.read_csv(file_name)\n",
    "\n",
    "# for tfidf or embedding csv file\n",
    "def process_feature_csv(df):\n",
    "    features = df.iloc[:, 26:].to_numpy()\n",
    "    labels =  df[\"Toxicity\"].to_numpy()\n",
    "    return features, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_embedding.csv\")\n",
    "dev_df = pd.read_csv(\"dev_embedding.csv\")\n",
    "test_df = pd.read_csv(\"test_embedding.csv\")\n",
    "\n",
    "train_features, train_labels = process_feature_csv(train_df)\n",
    "dev_features, dev_labels = process_feature_csv(dev_df)\n",
    "test_features, _ = process_feature_csv(test_df)\n",
    "test_ids = test_df[\"ID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 12165, 1: 2835})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(dev_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Supervised ML algorithm and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy 0.6834\n",
      "Precision score is  0.33584905660377357\n",
      "Recall score is  0.690652557319224\n",
      "F1_score is  0.451933064050779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "NBclf = GaussianNB()\n",
    "NBclf.fit(train_features, train_labels)\n",
    "\n",
    "print(\"Naive Bayes accuracy\", NBclf.score(dev_features, dev_labels))\n",
    "dev_preds = NBclf.predict(dev_features)\n",
    "precision_score, recall_score, fscore_score, _ = precision_recall_fscore_support(dev_labels, dev_preds, average=\"binary\")\n",
    "\n",
    "print(\"Precision score is \", precision_score)\n",
    "print(\"Recall score is \", recall_score)\n",
    "print(\"F1_score is \", fscore_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regressions accuracy 0.8336666666666667\n",
      "Precision score is  0.6523297491039427\n",
      "Recall score is  0.25679012345679014\n",
      "F1_score is  0.36851430017717035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LRclf = LogisticRegression(random_state=666, max_iter=300)\n",
    "LRclf.fit(train_features, train_labels)\n",
    "\n",
    "print(\"Logistic Regressions accuracy\", LRclf.score(dev_features, dev_labels))\n",
    "dev_preds = LRclf.predict(dev_features)\n",
    "precision_score, recall_score, fscore_score, _ = precision_recall_fscore_support(dev_labels, dev_preds, average=\"binary\")\n",
    "\n",
    "print(\"Precision score is \", precision_score)\n",
    "print(\"Recall score is \", recall_score)\n",
    "print(\"F1_score is \", fscore_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors accuracy 0.7926666666666666\n",
      "Precision score is  0.41590214067278286\n",
      "Recall score is  0.23985890652557318\n",
      "F1_score is  0.3042505592841163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNNclf = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "KNNclf.fit(train_features, train_labels)\n",
    "\n",
    "print(\"K-Nearest Neighbors accuracy\", KNNclf.score(dev_features, dev_labels))\n",
    "\n",
    "dev_preds = KNNclf.predict(dev_features)\n",
    "precision_score, recall_score, fscore_score, _ = precision_recall_fscore_support(dev_labels, dev_preds, average=\"binary\")\n",
    "\n",
    "print(\"Precision score is \", precision_score)\n",
    "print(\"Recall score is \", recall_score)\n",
    "print(\"F1_score is \", fscore_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = LRclf.predict(test_features).tolist()\n",
    "assert len(test_ids) == len(test_preds)\n",
    "\n",
    "f = open(\"test_predictions.csv\", \"w\")\n",
    "f.write(\"ID,Toxicity\\n\")\n",
    "for test_id, test_pred in zip(test_ids, test_preds):\n",
    "    f.write(str(test_id) + \",\" +str(test_pred) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Rule baseline accuracy 0.811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "ZEROclf = DummyClassifier(strategy=\"most_frequent\")\n",
    "ZEROclf.fit(train_features, train_labels)\n",
    "print(\"Zero Rule baseline accuracy\", ZEROclf.score(dev_features, dev_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Research Question 1: Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "unlabeled_df = pd.read_csv(\"unlabeled_embedding.csv\")\n",
    "unlabeled_features = unlabeled_df.iloc[:, 1:].to_numpy()\n",
    "\n",
    "unlabeled_labels = np.array([-1] * unlabeled_features.shape[0])\n",
    "\n",
    "semi_features = np.concatenate((train_features, unlabeled_features), axis=0)\n",
    "semi_labels = np.concatenate((train_labels, unlabeled_labels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self Training (Semi supervised Learning) accuracy 0.8302666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "LRclf = LogisticRegression(random_state=666, max_iter=300)\n",
    "self_training_model = SelfTrainingClassifier(LRclf)\n",
    "self_training_model.fit(semi_features, semi_labels)\n",
    "print(\"Self Training (Semi supervised Learning) accuracy\", self_training_model.score(dev_features, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SelfTrainingClassifier' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [43]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dev_preds \u001B[38;5;241m=\u001B[39m \u001B[43mself_training_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdev_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m precision_score, recall_score, fscore_score, _ \u001B[38;5;241m=\u001B[39m precision_recall_fscore_support(dev_labels, dev_preds, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrecision score is \u001B[39m\u001B[38;5;124m\"\u001B[39m, precision_score)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'SelfTrainingClassifier' object is not callable"
     ]
    }
   ],
   "source": [
    "dev_preds = self_training_model(dev_features)\n",
    "precision_score, recall_score, fscore_score, _ = precision_recall_fscore_support(dev_labels, dev_preds, average=\"binary\")\n",
    "\n",
    "print(\"Precision score is \", precision_score)\n",
    "print(\"Recall score is \", recall_score)\n",
    "print(\"F1_score is \", fscore_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# LRclf = LogisticRegression(random_state=666, max_iter=300)\n",
    "self_training_model = SelfTrainingClassifier(NBclf)\n",
    "self_training_model.fit(semi_features, semi_labels)\n",
    "\n",
    "print(\"Self Training (Semi supervised Learning) accuracy\", self_training_model.score(dev_features, dev_labels))\n",
    "dev_preds = self_training_model(dev_features)\n",
    "precision_score, recall_score, fscore_score, _ = precision_recall_fscore_support(dev_labels, dev_preds, average=\"binary\")\n",
    "\n",
    "print(\"Precision score is \", precision_score)\n",
    "print(\"Recall score is \", recall_score)\n",
    "print(\"F1_score is \", fscore_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "self_training_model = SelfTrainingClassifier(KNNclf)\n",
    "self_training_model.fit(semi_features, semi_labels)\n",
    "print(\"Self Training (Semi supervised Learning) accuracy\", self_training_model.score(dev_features, dev_labels))\n",
    "\n",
    "dev_preds = self_training_model(dev_features)\n",
    "precision_score, recall_score, fscore_score, _ = precision_recall_fscore_support(dev_labels, dev_preds, average=\"binary\")\n",
    "\n",
    "print(\"Precision score is \", precision_score)\n",
    "print(\"Recall score is \", recall_score)\n",
    "print(\"F1_score is \", fscore_score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}